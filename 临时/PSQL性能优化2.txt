优化分了三个部分的内容：查询类，更新类，管理类

查询类：work_mem参数

    该参数是postgresql每个进程可以使用的工作内存空间。如果进程需要的容量超过了这个范围，就要把处理内容输出到临时文件里，相当于OS的swap处理。
    查询时如果用到了排序，哈希关联，bitmap检索等方式的话，就要分别利用work_mem的内存空间。也就是一个SQL语句可能会同时使用多个工作内存空间，而不是共用一个。
    设置这个参数的时候，就要考虑到同时连接数以及每个连接平均使用的内存空间数。总内存数减去 （同时连接数”平均使用数的总和），剩下的才是OS和postgresql可以利用的缓存。（参考值，不是绝对值） 设置的太大的话，反倒会引起OS的swap，影响性能。
  
  正确设置work_mem的方法如下：
  1) psql连接数据库
  2）database=# set client_min_messages='LOG'; 
  3) database=# set log_temp_files = 0; //显示所有使用临时文件的日志
  4) 执行比较慢的SQL语句
  5) 如果显示了类似下列的日志的话，就要加大work_mem的值，然后重复第五步
     LOG: temporary file: path "base/pgsql_tmp/pgsql_tmp27660.1568", size 88155700
 
  修改这个参数不用重启数据库，reload一下就可以了。
  最好先执行一下SQL语句，把需要的资源全部放到缓存里，然后再调试，可以排除IO的影响。

查询类：random_page_cost参数和effective_cache_size参数

  索引可以增加查询效率，而该参数的设置会影响数据库是否积极地使用索引。
  默认的索引是树状结构，根据索引来检索数据的时候，是根据索引的匹配结果再到实际表中的对应位置读取数据。从磁盘的角度来讲，这种读取数据的方式叫做乱序读取（正式叫法不清楚...）。 相反，不利用索引，直接扫描表的方式叫做顺序读取。 
  乱序读取当然比顺序读取要慢。而postgresql用random_page_cost参数来设置乱序读取要比顺序读取慢多少（倍）。
  现在我们使用的新服务器的内存比数据库要大3倍，所以理论上所有的数据都能放入内存。这样的话，乱序读取和顺序读取的效率不会差多少。而默认的4倍就不合适了。这次我们把它设置为1，也就是说和顺序读取一样的效率，让数据库积极的使用索引来检索数据。
  另外，effective_cache_size参数是告诉数据库，OS的缓存大小。越大，数据库使用索引的积极性就越高。因为数据很可能在os的缓存里，乱序读取的效率也不差。这个值理论上等于OS可以使用的缓存大小。
  
  验证方法：
  
  一个很简单的方法就是查看是否使用了Bitmap位图扫描规划。
  位图扫描规划是Bitmap Index Scan和Bitmap Heap Scan的组合。先用Bitmap Index Scan通过索引，把匹配结果放到位图表（这个表会使用work_mem设置的大小，超过就要写入到临时文件，影响效率），在通过这个位图表循序读取数据库表（Bitmap Heap Scan），返回最终结果。

  从理论上来说，性能按照 索引扫描 > 位图扫描 > 顺序扫描  的顺序由高到低排列。
  
  如果你的服务器的内存没这么富裕，可以通过pg_statio_user_tables和pg_statio_user_indexes表查看每个表和索引的缓存程度。
  根据表的缓存程度，调节相关的SQL语句查询时的设置值。

查询类：shared_buffers参数

  大家都很熟悉的参数吧，共享内存的大小当然是越大越好啦。先别急，再仔细想想。

读数据时：
  数据库先在共享内存里查找，找不到的话，再检索磁盘。检索磁盘时先查OS的缓存，找不到的话才会实际扫描磁盘。然后把数据放到OS的缓存，再返回给数据库，也就是放到共享内存里面。
  按照这个逻辑，同一份数据，同时存在于OS的缓存和数据库的共享内存里面。 如果OS的缓存太小的化，就会放生swap，把数据放到磁盘里，当然效率也就会降低了。

写数据时：
  和读数据相反，先更新共享内存里面的内容，攒到一定数量或者到了一定时间段，再把更新的数据反应给OS。OS也是先更新到缓存，再实际更新到磁盘里。
  如果需要更新的数据超过了OS的缓存，更新处理会等OS整理缓存以得到可利用的空间。
  更新处理比较多的数据库，或者vacuum处理的时候，需要占用大量OS缓存。一定时间内无法确保到需要的空间时，数据库服务也有可能会停止。

综上所述，共享内存的值与OS的缓存一致是比较安全的。 
如果以检索为主的话，共享内存大一些也没什么问题吧。当然前提是数据库基本都能放到共享内存里。

查询类的几个参数可以用以下的关系表示。

物理内存 ＝ work_mem " 最大同时连接数" 平均使用work_mem数 ＋ shared_buffers ＋ effective_cache_size

以上公式只适用于数据库专用服务器的场合。


更新类：wal_sync_method参数

  向磁盘强制更新 WAL 数据的方法。在linux环境里可以使用fsync，fdatasync，open_sync三种方式。那种方式最快呢？可以用postgresql代码里面的test_fsync这个工具来测试。8.3版本以后才有这个工具好像。。。。

$ cd (源代码)postgresq-8.4.5/src/tools/fsync
$make
$./test_fsync

然后设置为其中最快的一种方式就行了。

例子：
open o_sync, write 8.xxx
write, fdatasync 4.xxxx
write, fsync 　4.xxxx

默认的fsync方式最快。 这个结果随着硬件和OS的不同会有很大的变化，系统有什么变更的时候，最好执行以下看看。

更新类：checkpoints相关参数

checkpoint就是把共有内存里面更新过的数据写道磁盘（磁盘缓存）里面的处理。有两个参数控制写入的时机和频率，两个参数同时有效，满足任何一个条件都会执行写入处理。（应该是。。^_^;）

checkpoint_segments：定量，写入大小。 一个是16MB，默认是3，所以就是48MB。到了这个量就会调用写入处理。
checkpoint_timeout：定时，写入间隔。默认是5min（五分种）。过了5分钟就调入写入处理。

这两个参数很容易理解，而判断设置的合适不合适，就要看实际的运用了。
如果日志文件里面频繁出现下列的提示，就要考虑调整上述两个参数了。

HINT: Consider increasing the configuration parameter "checkpoint_segments".
LOG: checkpoints are occurring too frequently (25 seconds apart)

这个提示说明，共享内存里面的数据更新的很频繁，就算写入磁盘之后，马上又会被更新。这时就可以加大一下写入间隔和写入大小，再看看效果。但是如果在vacuum或者在定时处理的时候出现上述提示的话，基本可以不理会。

另外还有一个参数，checkpoint_completion_target，是控制写入处理的分步程度的。
默认是0.5，也就是说，一次需要写入的内容，实际上不是一次全部完成，而是在写入间隔中分步完成的。

例如：
checkpoint_timeout是5分钟，而checkpoint_completion_target是0.5的话，
那么实际上是用了2分30秒来分步写入变更过的数据。每次写入不需要大量的缓存，可以加快写入效率。
当然是越分步越好了，所以推荐设置成0.9。 当然不能超过1啦，会跟下一次的写入发生冲突。


更新类：wal_buffers参数

WAL数据用到的内存大小。将使用OS的内存，而不是postgresql的空闲内存。更新大量数据的时候，写入处理会使用这个空间，加快写入速度。 更改之后需要重新启动数据库，所以事先设置得大一点比较方便。比如5MB。

注：这个参数不太明白。。。。 m(__)m

管理类：maintenance_work_mem参数

    这个参数表明VACUUM或者REINDEX处理可以使用的内存空间。基本上只有一个用户在指定时间（半夜）运行此类的处理，所以可以设置的大方一点。这次服务器的内存足够用，所以设置成最大值1GB。

管理类：autovacuum相关参数

  8.4的版本优化了autovacuum的速度。把一个表里面的页面（page）信息放到位图表里管理，每次读入需要处理的页面，在页面里先调整数据的配置关系后再写入数据。
  而普通的VACUUM命令和以前一样，速度没有进步。
  默认上是推荐使用autovacuum，不过在使用pgpool之类的同步数据的时候，会有锁表的处理，这时如果正好在autovacuum的话，就会发生延迟，影响效率。所以这次还是禁用了autovacuum，还是原来的vacuum在半夜定时处理。

  另外，如果使用autovacuum的话，可以设置同时启动几个进程。这个参数是maintenance_work_mem，默认是3，也就是说，会有3个autovacuum随时执行。
  在导入数据的时候，autovacuum也会同时运行，服务器性能没那么好的时候，还是先关掉autovacuum之后在导数据比较快。